<!-- Generated by SpecStory -->

# Untitled (2025-05-25 18:58:32)

_**User**_

Read @TODO.md and code

---

_**Assistant**_



---

Okay, I've reviewed the `TODO.md` file. It seems like there's a potential discrepancy in how the x/y offsets are calculated or interpreted in the `thumbfind.py` script. The example given suggests an expected vertical shift of 214 pixels, but the script reports a much smaller shift.

To understand this better, I'll first read the `src/vidkompy/thumbfind.py` script to see how these calculations are performed. Then, I'll read the `varia/thumbfind1.md`, `varia/thumbfind2.md`, and `varia/thumbfind3.md` files for more context on the `thumbfind` functionality and its development.



---

Read file: src/vidkompy/thumbfind.py

---

Read file: varia/thumbfind1.md

---

Read file: varia/thumbfind2.md

---

Read file: varia/thumbfind3.md

---

I've read `src/vidkompy/thumbfind.py`, `varia/thumbfind1.md`, `varia/thumbfind2.md`, and `varia/thumbfind3.md`.

Here's a summary of my understanding and a plan to address the issue from `TODO.md`:

**Understanding the Coordinate System and Issue:**

*   The `thumbfind.py` script calculates `x_shift` and `y_shift` which represent the top-left corner of the found thumbnail within the background image.
*   The `TODO.md` example implies:
    *   Foreground (FG): `tests/fg1.mp4` (likely 1920x684 based on the output in `TODO.md`)
    *   Background (BG): `tests/bg1.mp4` (the `TODO.md` output shows `bg2.mp4` as background, but the command uses `bg1.mp4`, this might be a typo in the TODO or the example output. The BG size is 1920x1080)
    *   Expected alignment: If FG is 1920x684 and BG is 1920x1080, and they are horizontally aligned at x=0, the vertical center alignment would mean `y = (1080 - 684) / 2 = 396 / 2 = 198`.
    *   The `TODO.md` states "a perfect alignment ... would be something like scale 100% x 0 y 214". This suggests the foreground, when placed at (0, 214) on the background, aligns perfectly. This implies the common content starts 214 pixels from the top of the background.
*   The script's output in `TODO.md` shows: `Scale: 97.14%, X shift: 3, Y shift: 120`. This is significantly different from the expected `y=214` (or `y=198` for center alignment).

**Key Observations from `thumbfind.py`:**

*   The script uses a multi-precision approach, combining histogram correlation, template matching (parallelized), and feature-based matching (AKAZE, ORB, SIFT).
*   `multiscale_template_matching` and `parallel_multiscale_template_matching` use `cv2.matchTemplate` with `TM_CCOEFF_NORMED`. `cv2.minMaxLoc` returns the top-left corner of the template match.
*   `feature_based_matching` and `enhanced_feature_matching` use homography or affine transformations. The extracted `tx`, `ty` are the translation components, which also represent the top-left corner of the transformed template in the background.
*   `precise_refinement` directly computes correlation in a small window and returns the `x, y` of the top-left corner of the best matching region.
*   The `_find_thumbnail_in_frames` method aggregates results from `multi_precision_matching`. The `x_shift` and `y_shift` returned are directly from the `best_result`'s `x` and `y` attributes, which correspond to the top-left corner of the *scaled foreground* within the *background*.

**Interpreting `(x, y)`:**

The `(x, y)` coordinates returned by `cv2.matchTemplate` (and subsequently by the feature matching homography's translation part) represent the **top-left corner of where the (potentially scaled) foreground template is found within the background image.**

If the foreground `fg1.mp4` (1920x684) is simply letterboxed within `bg1.mp4` (1920x1080) and centered, then:
*   `x_offset` should be `(1920 - 1920) / 2 = 0`.
*   `y_offset` should be `(1080 - 684) / 2 = 198`.

The user in `TODO.md` expects `y=214` for a "perfect alignment" at 100% scale. This means the *content* of `fg1.mp4` starts 214 pixels down from the top of `bg1.mp4`.

**Possible Reasons for Discrepancy:**

1.  **Content Mismatch/Actual Offset:** The actual content alignment in the sample files (`tests/fg1.mp4` and `tests/bg1.mp4`) might indeed result in an optimal match at `(3, 120)` with a slight scale difference, and the user's expectation of `(0, 214)` might be based on a different manual assessment or a different pair of files.
2.  **Algorithm Nuances:**
    *   **Scaling affecting coordinates:** Template matching is done with a scaled template. The `best_loc` is found on the image being searched. If the *background* was scaled for matching, the coordinates need to be scaled back. However, the current `multiscale_template_matching` scales the *template* and matches it against the *original grayscale background*. The `precise_refinement` also scales the template.
    *   **Feature matching homography:** The homography `H` transforms points from the foreground to the background. `H[0,2]` (tx) and `H[1,2]` (ty) are the translations of the foreground's origin (0,0) in the background's coordinate system. This should correctly give the top-left position.
3.  **Dominant Features:** The algorithms might be locking onto features that are slightly offset from what a human would perceive as the "true" alignment, especially if there are repetitive patterns or very similar regions near the actual best match.
4.  **Precision Levels:** The chosen precision level and the combination of algorithms might influence the final result. The example uses `-p 3` (Fine).
5.  **Averaging/Bias:** The script has logic for averaging results and preferring unity scale. This might shift the result slightly. The log shows "Preferring unity scale result" was *not* the case for the best result, but "Precise refinement did not improve result" suggests the `best_result` before refinement was already (3, 120) at 97.14% scale with 0.9911 confidence.
6.  **Frame Selection:** The script extracts a certain number of frames (`-n 8`) and averages/selects the best match among them. If the content varies significantly, this could lead to a compromise.

**Plan:**

1.  **Verify File Usage:** Double-check that the `TODO.md` example output (`vlveo-toronto-aisha2.mp4` vs `vlveo-toronto-aisha3_starlight.mp4`) matches the command-line arguments (`tests/fg1.mp4 tests/bg1.mp4`). It seems the `TODO.md` used different files for its summary table than for the command invocation shown. The paths in the table (`vlveo-toronto-aisha2.mp4`, `vlveo-toronto-aisha3_starlight.mp4`) are not in the project layout. I will assume the command `python -m vidkompy find tests/fg1.mp4 tests/bg1.mp4 -n 8 -p 3 -u` and its output in the `TODO.md` are the source of truth for the discrepancy investigation.
2.  **Isolate a Single Frame Pair:** To simplify, I will modify the script or use it in a way that it processes only the *first* frame of `fg1.mp4` and `bg1.mp4`. This will remove variability from frame averaging.
3.  **Focus on 100% Scale:** To match the user's "scale 100% x 0 y 214" expectation, I'll try to force the script to evaluate or heavily prioritize 100% scale. The `--unity_scale` flag (`-u`) is already used, which is good.
4.  **Debug `precise_refinement`:** The `precise_refinement` function seems critical. I'll examine its inputs and outputs more closely when a near-100% scale is found by prior levels.
5.  **Examine `multiscale_template_matching` at 1.0 scale:** See what `cv2.matchTemplate` returns for `scale = 1.0` directly. The coordinates `(x, y)` returned by `cv2.minMaxLoc(result)` are the top-left corner where the (unscaled) `resized_template` (which is `template_gray` at `scale=1.0`) matches `image_gray`. This should directly correspond to the expected `(x,y)` offset.

Let's start by ensuring we understand the coordinate system of the core matching function, `cv2.matchTemplate`.
If `template` is `FG_frame` and `image` is `BG_frame`, and `cv2.matchTemplate(image, template, ...)` gives `max_loc = (x, y)`, then `FG_frame` is found starting at `BG_frame[y:y+FG_frame.shape[0], x:x+FG_frame.shape[1]]`. This seems correct and is how it's used.

The `TODO.md` notes: "0,0 means that the gf & bg are aligned top-left, right?". Yes, if the result is `(0,0)` at `scale=1.0`, it means the foreground image, without scaling, aligns perfectly with the top-left corner of the background image.

The discrepancy is quite large (120 vs. 214). This suggests either the user's expectation of where the content aligns is different from what the algorithm finds as the *visually most similar region*, or there's a specific part of the algorithm (perhaps scaling interaction or feature weighting) that's pulling the result away.

Given the information in `thumbfind[1-3].md` and `thumbfind.py`, the current implementation seems to follow standard practices for template and feature matching. The coordinates `x, y` consistently refer to the top-left placement of the (scaled) foreground onto the background.

Let's re-examine the `precise_refinement` function as it's the final step for high precision levels.
The `precise_refinement` function takes an `initial_x`, `initial_y`, and `initial_scale`. It then searches a small pixel radius around `(initial_x, initial_y)` and a small scale range around `initial_scale`.
It iterates `x_positions` and `y_positions`. For each `(x, y)` in this range and each `scale`:
1. Resizes `template_gray` to `resized_template` using `scale`.
2. Extracts `region = image_gray[y : y + new_height, x : x + new_width]`.
3. Computes correlation between `resized_template` and `region`.
The `(x, y)` here are directly the top-left coordinates in `image_gray`. This seems correct.

The example output from `TODO.md`:
`Level 3 (Fine): scale = 99.68%, pos = (3, 111), confidence = 0.981`
Then: `INFO: Applying precise refinement...`
The final result table then shows: `X shift: 3, Y shift: 120`, with confidence 99.11%.
The `scale_down_pct` is 97.14%.

This means `precise_refinement` took `initial_scale=0.9968`, `initial_x=3`, `initial_y=111` and produced `scale=0.9714`, `x=3`, `y=120`, `confidence=0.9911`.
It seems that the "precise refinement" actually *changed* the scale from ~99.7% to ~97.1% and shifted Y from 111 to 120, and this resulted in a higher confidence (0.9911 vs 0.981 from Level 3).

This change during precise refinement might be the key. The user expects 100% scale and y=214. The algorithm finds ~97% scale and y=120 as a better match.

What if the `fg1.mp4` and `bg1.mp4` files *do not* have a 100% scale match where the content aligns at y=214? The algorithm might be correctly finding the *actual* best match, which is slightly scaled and at a different position.

Let's verify the files referenced in the `TODO.md` output table.
The table says:
`FG file: vlveo-toronto-aisha2.mp4`
`BG file: vlveo-toronto-aisha3_starlight.mp4`
These are *not* `tests/fg1.mp4` and `tests/bg1.mp4`.

This is a critical point. The user is comparing an expectation for `tests/fg1.mp4` and `tests/bg1.mp4` (implied by the command `python -m vidkompy find tests/fg1.mp4 tests/bg1.mp4 ...`) with results obtained from `vlveo-toronto-aisha2.mp4` and `vlveo-toronto-aisha3_starlight.mp4`.

**Revised Plan:**

1.  **Clarify File Discrepancy with User:** First, I need to ask the user to clarify which set of files the expectation (`scale 100% x 0 y 214`) applies to:
    *   `tests/fg1.mp4` and `tests/bg1.mp4` (as used in the command example in `TODO.md`)
    *   `vlveo-toronto-aisha2.mp4` and `vlveo-toronto-aisha3_starlight.mp4` (as listed in the output table in `TODO.md`)
    And confirm if these `vlveo...` files are available in the workspace or if they are external.

This clarification is essential before diving deeper into code changes. If the expectation is for files A,B but the results are from C,D, then the comparison is invalid.

It seems the user might have run the command with `tests/fg1.mp4` and `tests/bg1.mp4`, but then pasted a results table from a different run (perhaps with files that *do* have a known offset of (0, 214), or the `vlveo...` files are the actual `fg1`/`bg1` and the `tests/` prefix is just how they are stored locally).

Let's assume for a moment the `TODO.md` *intended* to use `tests/fg1.mp4` and `tests/bg2.mp4` (as per the "Foreground: fg1.mp4", "Background: bg2.mp4" lines just below the command in the `TODO.md` log) and that the `vlveo-...` names in the final table are just descriptive names for these test files.

The output summary also mentions:
`FG original size: 1920x684`
`BG original size: 1920x1080`

If FG (1920x684) is placed at `y=214` in BG (1920x1080), the bottom of FG would be at `214 + 684 = 898`. This fits within BG's height of 1080.
The remaining space at the bottom is `1080 - 898 = 182`.
The space at the top is `214`.
This is not a centered placement (`198` top, `198` bottom). This `y=214` must be specific to the content alignment.

**Let's assume the file paths in the command and the initial log lines ("Foreground: fg1.mp4", "Background: bg2.mp4") are the primary subject of the TODO, and the table with "vlveo" names is just a more descriptive output for those files.** The critical part is the reported numeric result: scale ~97%, x=3, y=120.

If the user is certain that for `tests/fg1.mp4` and `tests/bg2.mp4` (or `bg1.mp4`) the true alignment at 100% scale is `(0, 214)`, then the algorithm is indeed finding a different optimum.

Why would `precise_refinement` change scale from 99.68% to 97.14% and y from 111 to 120 *and increase confidence*?
This implies that at the slightly smaller scale and shifted y-position, the pixel-wise normalized cross-correlation (`self.compute_normalized_correlation`) is genuinely higher.

This could happen if:
*   The foreground object is slightly smaller in the background than in the foreground source.
*   There are compression artifacts or minor differences that make a slightly scaled-down version a better pixel-level match.
*   The `initial_x, initial_y` passed to `precise_refinement` (3, 111 from Level 3) is already a bit off from the user's (0, 214), and `precise_refinement` is just locally optimizing from that starting point.

The path to `(3,111)` at `~99%` scale comes from `Level 3 (Fine)`.
`Level 2 (Balanced): scale = 98.89%, pos = (10, 114), confidence = 0.968`
`Level 1 (Coarse): scale = 88.9%, pos = (98, 154), confidence = 0.694`
`Level 0 (Ballpark): scale â‰ˆ 68.9%, confidence = 0.959`

It seems the algorithm progressively refines the position and scale.

Consider the `unity_scale` parameter (`-u` in the command).
In `_find_thumbnail_in_frames`:
```python
        # Apply unity scale preference if enabled
        unity_scale_result = None
        if unity_scale and unity_scale_results:
            # Find best unity scale result
            unity_scale_result = max(unity_scale_results, key=lambda r: r.confidence)

            # If unity scale result is competitive (within 10% confidence), prefer it
            confidence_threshold = 0.1 # This is a 0.1 absolute confidence difference, not 10% relative
            if best_result is None or unity_scale_result.confidence >= (
                best_result.confidence - confidence_threshold
            ):
                logger.debug(
                    f"Preferring unity scale result: confidence={unity_scale_result.confidence:.3f} vs scaled={best_result.confidence:.3f}"
                )
                best_result = unity_scale_result
```
The results table in `TODO.md` has:
`Alternative Analysis:

---

