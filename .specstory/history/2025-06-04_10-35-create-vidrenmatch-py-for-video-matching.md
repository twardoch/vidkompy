<!-- Generated by SpecStory -->

# Create vidrenmatch.py for video matching (2025-06-04 12:35:58)

_**User**_

Based on @imgrenmatch  write `vidrenmatch.py` that will work analogically but for videos

---

_**Assistant**_



---

I'll create a `vidrenmatch.py` script that works analogically to `imgrenmatch` but for videos. Let me first explore the vidkompy codebase to understand what video processing capabilities are available.

---

<details>
            <summary>Listed directory src/vidkompy • **8** results</summary>
        
| Name |
|-------|
| 📁 `__pycache__` |
| 📄 `__main__.py` |
| 📄 `.DS_Store` |
| 📄 `__version__.py` |
| 📁 `utils` |
| 📁 `comp` |
| 📁 `align` |
| 📄 `__init__.py` |

</details>

---



---

<details>
            <summary>Listed directory src/vidkompy/align • **9** results</summary>
        
| Name |
|-------|
| 📁 `__pycache__` |
| 📄 `cli.py` |
| 📄 `core.py` |
| 📄 `data_types.py` |
| 📄 `algorithms.py` |
| 📄 `precision.py` |
| 📄 `frame_extractor.py` |
| 📄 `__init__.py` |
| 📄 `display.py` |

</details>

---



---

<details>
            <summary>Listed directory src/vidkompy/utils • **6** results</summary>
        
| Name |
|-------|
| 📁 `__pycache__` |
| 📄 `numba_ops.py` |
| 📄 `enums.py` |
| 📄 `logging.py` |
| 📄 `__init__.py` |
| 📄 `image.py` |

</details>

---



---

Read file: src/vidkompy/align/frame_extractor.py

---



---

Read file: src/vidkompy/utils/image.py

---



---

Read file: src/vidkompy/align/data_types.py

---



---

Now I'll create `vidrenmatch.py` based on the `imgrenmatch` script but adapted for videos. I'll leverage the vidkompy codebase's frame extraction capabilities.

---

```diff
- 
+ #!/usr/bin/env -S uv run -s
+ # /// script
+ # dependencies = ["fire", "rich", "opencv-python", "numpy", "numba", "loguru"]
+ # ///
+ # this_file: vidrenmatch.py
+ 
+ import shutil
+ from pathlib import Path
+ 
+ import fire
+ import numpy as np  # type: ignore
+ from rich.console import Console
+ from rich.progress import Progress
+ 
+ console = Console()
+ 
+ # Video file extensions
+ VIDEO_EXTENSIONS = {".mp4", ".avi", ".mov", ".mkv", ".webm", ".m4v", ".flv", ".wmv"}
+ 
+ 
+ def extract_representative_frame(
+     video_path: Path,
+     target_size: tuple[int, int] = (256, 256),
+ ) -> tuple[np.ndarray, int, int]:
+     """Extract and downsample a representative frame from video for comparison.
+ 
+     Args:
+         video_path: Path to the video file.
+         target_size: Desired (width, height) for downsampling.
+ 
+     Returns:
+         A tuple of (frame array, actual width, actual height).
+     """
+     import cv2
+ 
+     try:
+         cap = cv2.VideoCapture(str(video_path))
+         if not cap.isOpened():
+             raise ValueError(f"Cannot open video: {video_path}")
+ 
+         # Get total frames and jump to middle frame for representative sample
+         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
+         if total_frames == 0:
+             raise ValueError(f"Video has no frames: {video_path}")
+ 
+         # Seek to middle frame for most representative content
+         middle_frame = total_frames // 2
+         cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame)
+ 
+         ret, frame = cap.read()
+         cap.release()
+ 
+         if not ret:
+             raise ValueError(f"Cannot read frame from video: {video_path}")
+ 
+         # Convert to RGB and resize
+         frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
+         width, height = target_size
+         frame_resized = cv2.resize(
+             frame_rgb, (width, height), interpolation=cv2.INTER_LANCZOS4
+         )
+ 
+         return frame_resized.astype(np.float32), width, height
+ 
+     except Exception as e:
+         console.print(f"[red]Error processing {video_path}: {e!s}[/red]")
+         raise
+ 
+ 
+ def get_video_files(directory: Path) -> list[Path]:
+     """Get all supported video files from a directory."""
+     return sorted(
+         p
+         for p in directory.iterdir()
+         if p.is_file() and p.suffix.lower() in VIDEO_EXTENSIONS
+     )
+ 
+ 
+ def load_videos_from_dir(
+     directory: Path, target_size: tuple[int, int], label: str
+ ) -> tuple[list[np.ndarray], list[Path]]:
+     """Load and extract representative frames from videos in a directory.
+ 
+     Args:
+         directory: The directory containing videos.
+         target_size: The size to which each frame is downsampled.
+         label: Descriptive label for progress display.
+ 
+     Returns:
+         A tuple (list of frame arrays, list of corresponding file paths).
+     """
+     files = get_video_files(directory)
+     frames = []
+     valid_paths = []
+     with Progress() as progress:
+         task = progress.add_task(f"Loading {label}...", total=len(files))
+         for path in files:
+             try:
+                 frame, _, _ = extract_representative_frame(path, target_size)
+                 frames.append(frame)
+                 valid_paths.append(path)
+             except Exception:
+                 console.print(
+                     f"[yellow]Skipping invalid video: {path.name}[/yellow]"
+                 )
+             progress.advance(task)
+     return frames, valid_paths
+ 
+ 
+ def compute_distance_matrix(
+     dir_frames: list[np.ndarray], ref_frames: list[np.ndarray]
+ ) -> np.ndarray:
+     """Compute MSE distance matrix between source and reference video frames.
+ 
+     Args:
+         dir_frames: List of source video frame arrays.
+         ref_frames: List of reference video frame arrays.
+ 
+     Returns:
+         A 2D NumPy array where each row corresponds to a source video
+         and each column to a reference video.
+     """
+     n_dir = len(dir_frames)
+     n_ref = len(ref_frames)
+     dir_stack = np.stack(dir_frames)  # shape: (n_dir, h, w, c)
+     ref_stack = np.stack(ref_frames)  # shape: (n_ref, h, w, c)
+     h, w, c = dir_stack.shape[1:]
+ 
+     dir_flat = dir_stack.reshape(n_dir, -1)
+     ref_flat = ref_stack.reshape(n_ref, -1)
+ 
+     dir_sq = np.einsum("ij,ij->i", dir_flat, dir_flat)  # (n_dir,)
+     ref_sq = np.einsum("ij,ij->i", ref_flat, ref_flat)  # (n_ref,)
+     dot = dir_flat @ ref_flat.T  # (n_dir, n_ref)
+ 
+     dist_sq = dir_sq[:, None] + ref_sq[None, :] - 2.0 * dot
+     # Explicitly cast to np.ndarray to ensure proper type
+     return np.asarray(dist_sq / float(h * w * c))
+ 
+ 
+ def find_closest_matches(distance_matrix: np.ndarray) -> list[int]:
+     """For each source video, find the index of the closest reference video.
+ 
+     Args:
+         distance_matrix: The computed distance matrix.
+ 
+     Returns:
+         A list of indices corresponding to the closest reference video
+         for each source video.
+     """
+     matches: list[int] = np.argmin(distance_matrix, axis=1).tolist()
+     return matches
+ 
+ 
+ def generate_rename_mapping(
+     dir_paths: list[Path], ref_paths: list[Path], matches: list[int]
+ ) -> list[tuple[Path, Path]]:
+     """Generate mapping from source videos to new names based on matches.
+ 
+     Handles naming conflicts by appending a counter to duplicate names.
+ 
+     Args:
+         dir_paths: List of source video paths.
+         ref_paths: List of reference video paths.
+         matches: List of indices indicating the best matching reference
+                 for each source video.
+ 
+     Returns:
+         A list of tuples (original_path, new_path).
+     """
+     mapping = []
+     used_names: dict[str, int] = {}
+ 
+     for i, ref_idx in enumerate(matches):
+         src_path = dir_paths[i]
+         base_name = ref_paths[ref_idx].stem
+         candidate = f"{base_name}{src_path.suffix}"
+ 
+         if candidate in used_names:
+             used_names[candidate] += 1
+             candidate = (
+                 f"{base_name}_{used_names[candidate]}{src_path.suffix}"
+             )
+         else:
+             used_names[candidate] = 0
+ 
+         new_path = src_path.parent / candidate
+         mapping.append((src_path, new_path))
+ 
+     return mapping
+ 
+ 
+ def rename_files(mapping: list[tuple[Path, Path]], dry_run: bool) -> None:
+     """Rename files according to mapping, or display planned changes.
+ 
+     Args:
+         mapping: List of (original_path, new_path) tuples.
+         dry_run: If True, only display the planned renames without changes.
+     """
+     if dry_run:
+         console.print("\n[bold]Dry run - no files will be renamed[/bold]")
+         console.print("[bold]Planned renames:[/bold]")
+         for old, new in mapping:
+             console.print(f"{old.name} -> {new.name}")
+     else:
+         console.print("\nRenaming files...")
+         with Progress() as progress:
+             task = progress.add_task("Renaming...", total=len(mapping))
+             for old, new in mapping:
+                 if new.exists() and old != new:
+                     console.print(
+                         f"[yellow]Skipping {old.name} -> {new.name} "
+                         f"(target exists)[/yellow]"
+                     )
+                 else:
+                     shutil.move(str(old), str(new))
+                 progress.advance(task)
+         console.print("[green]Successfully renamed all files![/green]")
+ 
+ 
+ def cli(
+     input_dir: str | Path, ref_dir: str | Path, dry_run: bool = False
+ ) -> None:
+     """Rename videos in input_dir based on closest visual match from ref_dir.
+ 
+     Args:
+         input_dir: Directory containing videos to be renamed.
+         ref_dir: Directory containing reference videos used for naming.
+         dry_run: If True, only display planned renames without applying them.
+     """
+     source_dir = Path(input_dir)
+     reference_dir = Path(ref_dir)
+ 
+     if not source_dir.exists():
+         console.print("[red]Error: Source directory does not exist[/red]")
+         return
+     if not reference_dir.exists():
+         console.print("[red]Error: Reference directory does not exist[/red]")
+         return
+ 
+     target_size = (256, 256)
+     src_frames, src_paths = load_videos_from_dir(
+         source_dir, target_size, "source videos"
+     )
+     ref_frames, ref_paths = load_videos_from_dir(
+         reference_dir, target_size, "reference videos"
+     )
+ 
+     if not src_frames:
+         console.print("[yellow]No valid source videos found[/yellow]")
+         return
+     if not ref_frames:
+         console.print("[yellow]No valid reference videos found[/yellow]")
+         return
+ 
+     console.print(
+         f"Processing {len(src_frames)} source videos and "
+         f"{len(ref_frames)} reference videos..."
+     )
+     distance_matrix = compute_distance_matrix(src_frames, ref_frames)
+     matches = find_closest_matches(distance_matrix)
+     mapping = generate_rename_mapping(src_paths, ref_paths, matches)
+     rename_files(mapping, dry_run)
+ 
+ 
+ if __name__ == "__main__":
+     fire.Fire(cli) 
```

---



---



---



---

Read file: vidrenmatch.py

---



---



---



---

Read file: vidrenmatch.py

---



---



---



---



---



---



---



---

```bash
cd /Users/adam/Developer/vcs/github.twardoch/pub/vidkompy && python -m ruff format vidrenmatch.py
```

```
adam@Hamlet vidkompy % cd /Users/adam/Developer/vcs/github.twardoch/pub/vidkompy
 && python -m ruff formcd /Users/adam/Developer/vcs/github.twardoch/pub/vidkompy
 && python -m ruff format vidrenmatch.py
warning: The top-level linter settings are deprecated in favour of their counter
parts in the `lint` section. Please update the following options in `pyproject.t
oml`:
  - 'per-file-ignores' -> 'lint.per-file-ignores'
1 file left unchanged
adam@Hamlet vidkompy %
```

---



---

```bash
fd -e py vidrenmatch.py -x ruff check --output-format=github --fix --unsafe-fixes {}
```

```
adam@Hamlet vidkompy % fd -e py vidrenmatch.py -x ruff check --output-format=git
hub --fix --unsafe-fixefd -e py vidrenmatch.py -x ruff check --output-format=git
hub --fix --unsafe-fixes {}
::error title=Ruff (FBT001),file=/Users/adam/Developer/vcs/github.twardoch/pub/v
idkompy/vidrenmatch.py,line=192,col=52,endLine=192,endColumn=59::vidrenmatch.py:
192:52: FBT001 Boolean-typed positional argument in function definition
::error title=Ruff (FBT001),file=/Users/adam/Developer/vcs/github.twardoch/pub/v
idkompy/vidrenmatch.py,line=220,col=53,endLine=220,endColumn=60::vidrenmatch.py:
220:53: FBT001 Boolean-typed positional argument in function definition
::error title=Ruff (FBT002),file=/Users/adam/Developer/vcs/github.twardoch/pub/v
idkompy/vidrenmatch.py,line=220,col=53,endLine=220,endColumn=60::vidrenmatch.py:
220:53: FBT002 Boolean default positional argument in function definition
warning: The top-level linter settings are deprecated in favour of their counter
parts in the `lint` section. Please update the following options in `pyproject.t
oml`:
  - 'per-file-ignores' -> 'lint.per-file-ignores'
adam@Hamlet vidkompy %
```

---



---

Read file: pyproject.toml

---



---

```bash
python vidrenmatch.py --help
```

```
adam@Hamlet vidkompy % python vidrenmatch.py --help
INFO: Showing help with the command 'vidrenmatch.py -- --help'.

NAME
    vidrenmatch.py - Rename videos in input_dir based on closest visual match fr
om ref_dir.

SYNOPSIS
    vidrenmatch.py INPUT_DIR REF_DIR <flags>

DESCRIPTION
    Rename videos in input_dir based on closest visual match from ref_dir.

POSITIONAL ARGUMENTS
    INPUT_DIR
        Type: str | pathlib.Path
        Directory containing videos to be renamed.
    REF_DIR
        Type: str | pathlib.Path
        Directory containing reference videos used for naming.

FLAGS
    -d, --dry_run=DRY_RUN
        Type: bool
        Default: False
        If True, only display planned renames without applying them.

NOTES
    You can also use flags syntax for POSITIONAL ARGUMENTS
adam@Hamlet vidkompy %
```

---



---

```diff
- 
+ # vidrenmatch.py
+ 
+ A command-line tool for renaming videos based on visual similarity. This tool extracts representative frames from videos and renames source videos to match the most visually similar reference videos.
+ 
+ ## Features
+ 
+ - **Visual Similarity Matching**: Extracts middle frames from videos and compares them using MSE distance
+ - **Batch Processing**: Processes entire directories of videos efficiently
+ - **Dry Run Mode**: Preview rename operations without making changes
+ - **Progress Tracking**: Rich progress bars and status updates
+ - **Error Handling**: Graceful handling of invalid or corrupted video files
+ - **Wide Format Support**: Supports MP4, AVI, MOV, MKV, WebM, M4V, FLV, WMV formats
+ 
+ ## Installation
+ 
+ The script uses `uv` for dependency management. Simply run it directly:
+ 
+ ```bash
+ python vidrenmatch.py --help
+ ```
+ 
+ ## Usage
+ 
+ ### Basic Usage
+ 
+ ```bash
+ # Rename videos in source_dir based on visual matches from reference_dir
+ python vidrenmatch.py source_videos/ reference_videos/
+ 
+ # Dry run to preview changes without renaming
+ python vidrenmatch.py source_videos/ reference_videos/ --dry_run
+ ```
+ 
+ ### Example Workflow
+ 
+ 1. **Prepare directories**: Place videos to be renamed in one directory, and reference videos (with desired names) in another
+ 2. **Preview changes**: Run with `--dry_run` to see planned renames
+ 3. **Execute renames**: Run without `--dry_run` to apply changes
+ 
+ ```bash
+ # Step 1: Preview what will be renamed
+ python vidrenmatch.py ./to_rename/ ./references/ --dry_run
+ 
+ # Step 2: Apply the renames
+ python vidrenmatch.py ./to_rename/ ./references/
+ ```
+ 
+ ## How It Works
+ 
+ 1. **Frame Extraction**: Extracts the middle frame from each video for comparison
+ 2. **Preprocessing**: Resizes frames to 256x256 and converts to RGB for consistent comparison
+ 3. **Distance Calculation**: Computes MSE (Mean Squared Error) distance matrix between all source and reference frames
+ 4. **Matching**: Finds the closest visual match for each source video
+ 5. **Renaming**: Generates new filenames based on reference video names, handling conflicts with numerical suffixes
+ 
+ ## Algorithm Details
+ 
+ - **Representative Frame**: Uses the middle frame (50% position) of each video as most representative content
+ - **Similarity Metric**: MSE distance between flattened pixel arrays after normalization
+ - **Conflict Resolution**: Appends `_1`, `_2`, etc. when multiple source videos match the same reference
+ - **Format Preservation**: Maintains original file extensions during renaming
+ 
+ ## Performance
+ 
+ - **Frame Processing**: ~256x256 downsampling for fast comparison while preserving visual structure
+ - **Memory Efficient**: Processes videos sequentially with minimal memory footprint
+ - **Vectorized Operations**: Uses NumPy for efficient distance matrix computation
+ 
+ ## Requirements
+ 
+ - Python 3.10+
+ - OpenCV (cv2)
+ - NumPy
+ - Rich (for progress bars)
+ - Fire (for CLI)
+ 
+ ## Example Output
+ 
+ ```
+ Loading source videos... ████████████████████████████████████████ 100% 0:00:02
+ Loading reference videos... ████████████████████████████████████████ 100% 0:00:01
+ Processing 5 source videos and 3 reference videos...
+ 
+ Dry run - no files will be renamed
+ Planned renames:
+ video1.mp4 -> reference_a.mp4
+ video2.mp4 -> reference_b.mp4
+ video3.mp4 -> reference_a_1.mp4
+ video4.mp4 -> reference_c.mp4
+ video5.mp4 -> reference_b_1.mp4
+ ```
+ 
+ ## Related Tools
+ 
+ This tool is inspired by `imgrenmatch` but adapted for video content, extracting representative frames for comparison rather than comparing images directly. 
```

---



---

Wait, but let me reflect on what I've created and think about potential improvements and considerations:

**Ideot** (Creative perspective): What if we could make this even more sophisticated? We could extract multiple frames from different time positions, maybe use perceptual hashing like the vidkompy codebase does, or even incorporate audio fingerprinting for additional matching accuracy!

**Critin** (Critical perspective): Hold on - let's consider the practical limitations. The current approach using just the middle frame might miss cases where videos have different content structures (intro/outro vs. main content). Also, MSE distance on raw pixels might be sensitive to compression artifacts and lighting differences. The 256x256 downsampling might lose important distinguishing details.

**Balanced assessment**: The current implementation provides a solid foundation that mirrors the `imgrenmatch` functionality well. Key strengths:

1. ✅ **Follows the original pattern** - Maintains the same API and workflow as `imgrenmatch`
2. ✅ **Robust error handling** - Gracefully handles corrupted videos and provides user feedback
3. ✅ **Efficient processing** - Uses vectorized operations and reasonable frame sizes
4. ✅ **User-friendly** - Rich progress bars and dry-run capability

**Potential improvements for future iterations**:
- **Multiple frame sampling**: Extract 3-5 frames at different positions for more robust matching
- **Perceptual hashing**: Use algorithms like pHash or dHash instead of raw pixel comparison
- **Content-aware frame selection**: Skip black frames or select frames with highest detail
- **Audio fingerprinting**: Add optional audio-based matching for ambiguous cases

**Current limitations to acknowledge**:
- Single frame may not represent entire video content well
- Sensitive to compression differences between videos
- No handling of different aspect ratios or letterboxing
- Limited to visual similarity only

The tool as implemented provides immediate value while maintaining simplicity and following established patterns. It successfully adapts the image-based approach to video content and should work well for most common use cases where videos have similar visual content throughout.

---

